{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9b6017-1454-4f60-9dd2-470c748a45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch import nn\n",
    "time = np.loadtxt(\"../Data/AAL/100408_timeseries.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261c13b7-01f8-4907-ab81-bd00e1e9269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d887e774-82ea-41a0-857e-69f6cb889d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 116)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86511be-9076-4648-b3c5-7791db5d7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import TimeSDataset\n",
    "Dataset = TimeSDataset(\"../Data/AAL/\",\"Gender\",label_path=\"../Data/Behavioral-HCP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6a0603-4837-417a-8c28-5ae8410617ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1200, 116]), tensor(1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data , label = next(iter(Dataset))\n",
    "data = torch.stack([data,data])\n",
    "data.shape , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f24530-f735-464b-a0f4-ced57705fd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5457ffc1-713b-4ec8-9c39-7f3d28568f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Config import Config\n",
    "from SplitWindows import SplitWindows\n",
    "import torch\n",
    "SplitedSeries = SplitWindows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2092a40-d2c3-4052-995e-9f21cd9d2a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 105, 116, 20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SplitedSeries.shape   # ( B , T , V , P )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9b6970-f1d2-4f54-ac6f-f81c87791545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680b5918-7f82-4812-9d6d-52f003cf869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AttentionArea import TemporalAttention , SpatialAttention\n",
    "TAttention = TemporalAttention (8 ,Config.V * Config.K_E , 32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c9e62e-3074-4658-9bdb-06b22227e2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 105, 116, 40]), torch.Size([2, 105, 105]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Temporal_output , weights = TAttention(SplitedSeries)\n",
    "# (B , T , V , K_E)\n",
    "Temporal_output.shape , weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad9c321d-8a1d-46f0-af28-c50a493d13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial_output = SAttention(Temporal_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d0b216c-f19e-407f-ab94-afeaa636a7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4640"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.V * Config.K_E \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e2c2e9-90d1-4a37-be19-641a8b8b4fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 105, 116, 116])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AttentionArea import DynamicMatrix\n",
    "DM = DynamicMatrix()\n",
    "weights = DM(Temporal_output)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d40853-4e05-4a4a-9092-271386de2eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 105, 116, 40])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from AttentionArea import SpatialAttention\n",
    "ST = SpatialAttention()\n",
    "SpatialOut = ST(Temporal_output)\n",
    "SpatialOut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6158e117-bf96-41e3-aadb-c2da52bed96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c2accc9-57dc-4bb0-ab0c-8ec504cbdce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1],\n",
       "        [  0,   8],\n",
       "        [  0,  12],\n",
       "        ...,\n",
       "        [115,  86],\n",
       "        [115,  93],\n",
       "        [115,  98]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1][1].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ebfa38d-aa56-443b-a9c0-cc866d63e703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1][1][0][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8012011-58a4-4825-924f-74d4fc869baa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Assuming x is your node features with shape (B, T, V, P)\n",
    "# and adj is your weighted adjacency matrix with shape (B, T, V, V)\n",
    "Batch = []\n",
    "\n",
    "gcn_layer = GCNConv(in_channels=Config.K_E, out_channels=Config.K_F)\n",
    "\n",
    "# Iterate over each graph in the batch\n",
    "for i in range(Config.BATCH_SIZE):\n",
    "    # Extract the adjacency matrix for the current graph\n",
    "    adj_i = weights[i]  # Shape (T, V, V)\n",
    "    out = []\n",
    "    for t in range(Config.T):\n",
    "        # Get the edge indices and weights for the current time step\n",
    "        edge_index = adj_i[t].nonzero(as_tuple=False).T  # Shape (2, E)\n",
    "        edge_weights = adj_i[t][edge_index[0], edge_index[1]]  # Shape (E,)\n",
    "        # print(edge_index)\n",
    "        # Select the corresponding node features for the current time step\n",
    "        x_t = SpatialOut[i][t]\n",
    "        # Apply the GCN layer\n",
    "        x_t = gcn_layer(x_t, edge_index, edge_weight=edge_weights)\n",
    "        # Store the output for the current time step\n",
    "        out.append(x_t)\n",
    "    Batch.append(torch.stack(out))\n",
    "\n",
    "# Stack the output to get the final representation\n",
    "out = torch.stack(Batch)  # Shape will depend on how you structure the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58856b5d-6418-47a2-a454-4555f0c3afd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 105, 116, 40])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d23d6-e344-47d8-8d48-f6be8eeb355b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
