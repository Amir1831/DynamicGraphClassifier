{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac9b6017-1454-4f60-9dd2-470c748a45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch import nn\n",
    "time = np.loadtxt(\"../Data/AAL/100408_timeseries.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d887e774-82ea-41a0-857e-69f6cb889d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 116)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f86511be-9076-4648-b3c5-7791db5d7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import TimeSDataset\n",
    "Dataset = TimeSDataset(\"../Data/AAL/\",\"Gender\",label_path=\"../Data/Behavioral-HCP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb6a0603-4837-417a-8c28-5ae8410617ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1200, 116]), tensor(1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data , label = next(iter(Dataset))\n",
    "data = torch.stack([data,data])\n",
    "data.shape , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8f24530-f735-464b-a0f4-ced57705fd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5457ffc1-713b-4ec8-9c39-7f3d28568f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Config import Config\n",
    "from SplitWindows import SplitWindows\n",
    "import torch\n",
    "SplitedSeries = SplitWindows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2092a40-d2c3-4052-995e-9f21cd9d2a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 20, 116])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SplitedSeries.shape   # ( B , T , P , V )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd9b6970-f1d2-4f54-ac6f-f81c87791545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "680b5918-7f82-4812-9d6d-52f003cf869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, hidden_dim, num_heads, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            embed_dim - Dimensionality of input and attention feature vectors\n",
    "            hidden_dim - Dimensionality of hidden layer in feed-forward network\n",
    "                         (usually 2-4x larger than embed_dim)\n",
    "            num_heads - Number of heads to use in the Multi-Head Attention block\n",
    "            dropout - Amount of dropout to apply in the feed-forward network\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads,\n",
    "                                          dropout=dropout)\n",
    "        self.layer_norm_2 = nn.LayerNorm(embed_dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(embed_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp_x = self.layer_norm_1(x)\n",
    "        x = x + self.attn(inp_x, inp_x, inp_x)[0]\n",
    "        x = x + self.linear(self.layer_norm_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, num_heads, input_dim, hidden_dim):\n",
    "        super(TemporalAttention, self).__init__()\n",
    "        self.attention = AttentionBlock(num_heads = num_heads, embed_dim = input_dim, hidden_dim = hidden_dim)\n",
    "        self.Conv1 = nn.Conv2d(Config.P , Config.K_E , kernel_size=(3,3),padding=1)\n",
    "        self.Conv2 = nn.Conv2d(Config.K_E , Config.K_E , kernel_size=(3,3),padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input : (B , T , P , V)\n",
    "        x = x.view(x.size(0) , x.size(2) , x.size(1) , x.size(3))  # Reshape to : (B , P , T , V)\n",
    "        ## Apply Conv2D \n",
    "        x = slef.Conv2(self.Conv1(x)) # Output of Conv : (B , K_E , T , V)\n",
    "        x = x.view(x.size(0) , x.size(2) , x.size(1) , x.size(3))  # Change back dimention to : (B , T , K_E , V)\n",
    "        ## Temporal Part \n",
    "        x = x.view(x.size(1), x.size(0), -1)  # merge spatial dims & Change dimention because \"Batch_First\" is Flase\n",
    "        x = self.attention(x)\n",
    "        x = x.view(x.size(1), x.size(0), x.size(2) // Config.V, x.size(2) // Config.P)  # restore spatial dims\n",
    "        return x\n",
    "TAttention = TemporalAttention(8 ,Config.V * Config.P , 32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19c9e62e-3074-4658-9bdb-06b22227e2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11, 20, 116])\n",
      "torch.Size([11, 2, 2320])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 20, 116])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Temporal_output = TAttention(SplitedSeries)\n",
    "Temporal_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c321d-8a1d-46f0-af28-c50a493d13af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
