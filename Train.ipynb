{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d5b3a9-45c0-458c-b691-a2c0ae39cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from SplitWindows import SplitWindows\n",
    "from AttentionArea import TemporalAttention , SpatialAttention , DynamicMatrix , AttentionBlock\n",
    "from torch_geometric.nn import GCNConv\n",
    "from Config import CONFIG\n",
    "from Dataset import TimeSDataset\n",
    "import engine\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "Config = CONFIG()\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bec1ab0-1ef0-4ce5-8278-b176448b31d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c6e644-2c51-42e2-a1c2-3f3a6b6038a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write the Main Class\n",
    "\n",
    "class DynDeepNet(nn.Module):\n",
    "    def __init__(self ):\n",
    "        super().__init__()\n",
    "        # Define Clf token\n",
    "        self.CLFToken = torch.rand(1, Config.T_prim, 1)\n",
    "        # Define Temporal Attention\n",
    "        self.TAttention = TemporalAttention (Config.NUM_H ,Config.V * Config.K_E , Config.HIDDEN_DIM)\n",
    "        # Define Spatial Attention \n",
    "        self.SAttention = SpatialAttention()\n",
    "        # Define Dynamic Matrix\n",
    "        self.Dm = DynamicMatrix()\n",
    "        # Define GCN Layer\n",
    "        self.gcn_layer = GCNConv(in_channels=Config.K_E, out_channels=Config.K_F)\n",
    "        # Define Final Encoder layers\n",
    "        self.Transformer = nn.Sequential(*[AttentionBlock(Config.T * Config.K_F, Config.HIDDEN_DIM, Config.NUM_H, Config.DROP_OUT) for _ in range(Config.NUM_LAYER)])\n",
    "        self.Mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(Config.T * Config.K_F),\n",
    "            nn.Linear(Config.T * Config.K_F, Config.NUM_CLASS)\n",
    "            # torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.Dropout = nn.Dropout(Config.DROP_OUT)\n",
    "        self.Flatten = nn.Flatten(2,-1)\n",
    "    def forward(self,x):\n",
    "        ### Input : (B , T_Prim , V)\n",
    "        B , _ , _ = x.shape\n",
    "        ## ADD CLF TOKEN\n",
    "        CLFToken = self.CLFToken.repeat(B, 1 ,1).to(device)\n",
    "        x = torch.concatenate([CLFToken, x], axis=-1)\n",
    "        \n",
    "        ## Convert Signal Serie to the Window Signal\n",
    "        x = SplitWindows(x)  ## OutPut : (B , T , V ,P)\n",
    "        ## Temporal Transformer\n",
    "        x = self.TAttention(x)  ## OutPut : (B , T , V , K_E)\n",
    "        ## Spatial Attention\n",
    "        x = self.SAttention(x)    ## OutPut : (B , T , V , K_E)\n",
    "        # Apply Drop out\n",
    "        x = self.Dropout(x)\n",
    "        ## Dynamic Matrix\n",
    "        A = self.Dm(x)           ## OutPut  : (B , T , V , V)\n",
    "        ## GCN Layer\n",
    "        BatchList = []\n",
    "        # Iterate over each graph in the batch\n",
    "        for i in range(B):\n",
    "            # Extract the adjacency matrix for the current graph\n",
    "            adj_i = A[i]  # Shape (T, V, V)\n",
    "            out = []\n",
    "            for t in range(Config.T):\n",
    "                # Get the edge indices and weights for the current time step\n",
    "                edge_index = adj_i[t].nonzero(as_tuple=False).T  # Shape (2, E)\n",
    "                edge_weights = adj_i[t][edge_index[0], edge_index[1]]  # Shape (E,)\n",
    "                # Select the corresponding node features for the current time step\n",
    "                x_t = x[i][t]\n",
    "                # Apply the GCN layer\n",
    "                x_t = self.gcn_layer(x_t, edge_index, edge_weight=edge_weights)\n",
    "                # Store the output for the current time step\n",
    "                out.append(x_t)\n",
    "            BatchList.append(torch.stack(out))\n",
    "        \n",
    "        # Stack the output to get the final representation\n",
    "        x = torch.stack(BatchList)  ## OUTPUT : (B , T , V , K_F) \n",
    "        # Transpose\n",
    "        x = x.transpose(1,2)  ## OUTPUT : (B , V , T , K_F)\n",
    "        # Flatten\n",
    "        x = self.Flatten(x)  ## OUTPUT  : (B , V , T * K_F)\n",
    "        # Drop Out\n",
    "        x = self.Dropout(x)\n",
    "        # Apply Final Encoder\n",
    "        x = x.transpose(0,1)\n",
    "        x = self.Transformer(x)   ## OUTPUT : (V , B , T * K_F)\n",
    "        # Apply Linear Head\n",
    "        cls = x[0]\n",
    "        return self.Mlp_head(cls)\n",
    "\n",
    "Model = DynDeepNet()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d7d41-3800-4c90-80df-1e0384cc996e",
   "metadata": {},
   "source": [
    "## Define Dataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9a94b8-f35b-4d70-b036-f6a15080f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset = TimeSDataset(\"../Data/AAL/Train\",\"Gender\",label_path=\"../Data/Behavioral-HCP.csv\")\n",
    "TestDataset = TimeSDataset(\"../Data/AAL/Test\",\"Gender\",label_path=\"../Data/Behavioral-HCP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100803ea-79c1-4c43-9393-9adeb9abed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataLoader = DataLoader(TrainDataset ,Config.B ,shuffle = True ,num_workers= 2)\n",
    "TestDataLoader = DataLoader(TestDataset ,Config.B ,shuffle = False ,num_workers= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46efd2-15da-41fd-a32f-06c06e60b00a",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa8c903-31ef-42b6-a441-83ac71ae5fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "LR = 0.001\n",
    "Pivot = 80\n",
    "Part = 1\n",
    "Epochs = 20\n",
    "save_weights = False\n",
    "###\n",
    "optimizer = torch.optim.AdamW(Model.parameters() , LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0dd7a5-2c55-439b-8a3e-3a20f3bcd9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                           | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1004.00 MiB. GPU 0 has a total capacty of 3.80 GiB of which 839.81 MiB is free. Process 11753 has 2.47 GiB memory in use. Of the allocated memory 2.33 GiB is allocated by PyTorch, and 43.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mTrainDataLoader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mTestDataLoader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mPivot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mPart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43msave_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mEpochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/Code/engine.py:175\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, Pivot, Part, save_weights, epochs, device)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 175\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    181\u001b[0m       dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m    182\u001b[0m       loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m    183\u001b[0m       device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Print out what's happening\u001b[39;00m\n",
      "File \u001b[0;32m/app/Code/engine.py:57\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     54\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# 4. Loss backward\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# 5. Optimizer step\u001b[39;00m\n\u001b[1;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1004.00 MiB. GPU 0 has a total capacty of 3.80 GiB of which 839.81 MiB is free. Process 11753 has 2.47 GiB memory in use. Of the allocated memory 2.33 GiB is allocated by PyTorch, and 43.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "results = engine.train(Model , \n",
    "                TrainDataLoader,\n",
    "                TestDataLoader,\n",
    "                optimizer,\n",
    "                loss_fn,\n",
    "                Pivot,\n",
    "                Part,\n",
    "                save_weights,\n",
    "                Epochs,\n",
    "                device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb65a5-2abf-4dc6-bb56-4c02fa8d5e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
